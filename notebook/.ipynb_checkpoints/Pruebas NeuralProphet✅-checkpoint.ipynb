{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2ce96f-d030-458a-b3bf-c29b22feb464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 1, 5, 12, 42, 26, 115916)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "principio = datetime.datetime.now()\n",
    "principio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8498ef6-87c2-4889-882c-f94864e19ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb8d261-6fec-4eed-aee9-130d64354b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/datos sin días.csv')\n",
    "df.columns = ['ds', 'y']\n",
    "df['ds']=pd.to_datetime(df['ds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cfc9d2-6d4f-48be-ac74-fbe00f085f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "  if np.any(y_true==0)==True:\n",
    "    print('Erro: y_true contêm zeros!')\n",
    "    return np.inf\n",
    "  else:\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33954105-cf22-4d96-b338-66c80aff9b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_last_n = 31\n",
    "train = df.iloc[:-exclude_last_n]\n",
    "test = df.iloc[-exclude_last_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b3b541-a353-4344-a875-c06214508e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# sp_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 30, 31, 36, 365, 366]\n",
    "# funcionperdida = ['MSE', 'MAE', 'Huber']\n",
    "# sm_values = [\"additive\", \"multiplicative\"]\n",
    "# tscv = TimeSeriesSplit(n_splits=5)  # Puedes ajustar el número de divisiones según tus necesidades\n",
    "\n",
    "# for h in funcionperdida:\n",
    "#     for i in sp_values:\n",
    "#         for j in sm_values:\n",
    "\n",
    "#             mape_scores = []\n",
    "    \n",
    "#             for train_index, test_index in tscv.split(train):\n",
    "#                 train_cv, test_cv = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "#                 model = NeuralProphet(\n",
    "#                     growth=\"linear\",\n",
    "#                     changepoints=None,\n",
    "#                     n_changepoints=15,\n",
    "#                     changepoints_range=0.8,\n",
    "#                     trend_reg=0,\n",
    "#                     trend_reg_threshold=False,\n",
    "#                     yearly_seasonality=\"auto\",\n",
    "#                     weekly_seasonality=\"auto\",\n",
    "#                     daily_seasonality=\"auto\",\n",
    "#                     seasonality_mode=j,\n",
    "#                     seasonality_reg=i,\n",
    "#                     n_forecasts=1,\n",
    "#                     n_lags=0,\n",
    "#                     epochs=50,\n",
    "#                     loss_func=h,\n",
    "#                     normalize=\"auto\",\n",
    "#                     impute_missing=True\n",
    "#                 )\n",
    "                \n",
    "#                 # Ajustar el modelo con el conjunto de entrenamiento actual\n",
    "#                 metrics = model.fit(train_cv, freq='D')\n",
    "    \n",
    "#                 # Hacer predicciones en el conjunto de prueba actual\n",
    "#                 future_cv = model.make_future_dataframe(train_cv, periods=len(test_cv), n_historic_predictions=len(train_cv))\n",
    "#                 forecast_cv = model.predict(future_cv)\n",
    "    \n",
    "#                 # Calcular el MAPE para el conjunto de prueba actual\n",
    "#                 y_true_cv = test_cv['y'].values\n",
    "#                 y_pred_cv = forecast_cv['yhat1'][-len(test_cv):].values\n",
    "#                 mape_cv = mean_absolute_percentage_error(y_true_cv, y_pred_cv)\n",
    "    \n",
    "#                 mape_scores.append(mape_cv)\n",
    "    \n",
    "#             avg_mape = np.mean(mape_scores)\n",
    "#             print(f'Con sr = {i}, lf: {h}, y sm: {j} AVG MAPE: {avg_mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bd86f-604f-4414-a82a-390535736a9d",
   "metadata": {},
   "source": [
    "Con sr = 12, lf: MSE, y sm: additive AVG MAPE: 114.99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5779a3dd-9288-4ecf-83b5-f3fd4d12d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n"
     ]
    }
   ],
   "source": [
    "model = NeuralProphet(\n",
    "            growth=\"linear\",    # Determine trend types: 'linear', 'discontinuous', 'off'\n",
    "            changepoints=None,  # list of dates that may include change points (None->automatic)\n",
    "            n_changepoints=15,\n",
    "            changepoints_range=0.8,\n",
    "            trend_reg=0,\n",
    "            trend_reg_threshold=False,\n",
    "            yearly_seasonality=\"auto\",\n",
    "            weekly_seasonality=\"auto\",\n",
    "            daily_seasonality=\"auto\",\n",
    "            seasonality_mode=\"additive\",\n",
    "            seasonality_reg=12,\n",
    "            n_forecasts=1,\n",
    "            n_lags=0, # modeificar\n",
    "            epochs=50, #  50\n",
    "            loss_func=\"MSE\",\n",
    "            normalize=\"auto\",   # Type of normalization ('minmax', 'standardize', 'soft', 'off')\n",
    "            impute_missing=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0af799b-5f75-4586-9df9-471c6b8833cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.93% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (23) is too small than the required number                     for the learning rate finder (229). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbbfb128dfd41088adc2a956badb94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795a3afea2524fa9bb2562831aa1f3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = model.fit(train, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05cfad07-286c-466f-9e94-5293320223aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.93% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.932% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.932% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.data.processing._handle_missing_data) - Dropped 31 rows at the end with NaNs in 'y' column.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5fc470e8764e36adcaf1f148bb662e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 23it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    }
   ],
   "source": [
    "future = model.make_future_dataframe(train, periods=len(test), n_historic_predictions=len(train))\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7228ce57-85b4-4588-8215-d106f1d84587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3704.73 ventas\n",
      "MAPE: 34.45%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = test['y'].values\n",
    "y_pred = forecast['yhat1'][-31:].values\n",
    "mae  = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "print(f'MAE:  {mae:.2f} ventas')\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5424071c-ca03-4a4b-b0ec-b2196cac76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-05 12:42:26.115916\n",
      "2024-01-05 12:42:56.232461\n",
      "0:00:30.116545\n"
     ]
    }
   ],
   "source": [
    "final = datetime.datetime.now()\n",
    "duracion = final-principio\n",
    "print(principio)\n",
    "print(final)\n",
    "print(duracion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralprophet",
   "language": "python",
   "name": "neuralprophet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
